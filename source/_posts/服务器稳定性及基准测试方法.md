---
title: 服务器稳定性及基准测试方法
comments: true
categories: [知识库]
date: 2025-09-11 15:40:24
keywords:
  - 服务器
  - 基准测试
  - 服务器压测
  - Stress-NG
  - Sysbench
  - 内存
  - CPU
  - 硬盘
tags:
  - 服务器
  - 基准测试
  - 服务器压测
  - Stress-NG
  - Sysbench
  - 内存
  - CPU
  - 硬盘
---

## 测试项

### CPU基准和稳定性测试

|测试项|测试工具|参考业务场景|
|---|---|---|
|浮点运算|Linpack|数据分析、大量数值计算、机器学习推理/训练|
|整数运算|sysbench cpu|Redis、Kafka|
|稳定性|Stress-NG|CPU、内存、IO全面压力测试|

### 内存基准和稳定性测试

<!-- more -->

|测试项|测试工具|参考业务场景|
|---|---|---|
|内存带宽|Stream Copy/Scale/Add/Triad|内存数据库（Redis）、大数据处理、Kafka 消息队列、缓存系统|
|压力测试|sysbench memory|压力测试，随机、顺序访问测试|
|稳定性测试|memtester|持续运行数小时,测试稳定性|

### 网络基准测试

|测试项|测试工具|参考业务场景|
|---|---|---|
|带宽极限|iperf3|测试带宽极限性能是否接近理论极限值|
|吞吐测试|netperf TCP_RR / UDP_RR|微服务 RPC、数据库访问、API 调用、Kafka 消息传输|

### 硬盘测试

|测试项|测试工具|参考业务场景|
|---|---|---|
|4k单队列|fio bs=4k iodepth=1|MySQL场景|
|4k 32队列|fio bs=4k iodepth=32|MongoDB场景|
|32k 32队列|fio bs=32k iodepth=32|高并发Web服务，Kafka日志刷盘，多线程缓存写入|
|1m 单队列|fio bs=1m iodepth=1|顺序读写，备份、视频流、镜像分发|
|1m 32队列|fio bs=1m iodepth=32|并发大文件读写，大规模备份，分布式存储，对象存储|

其中针对业务场景，根据单台服务器部署的业务数量适当设置`numjobs`以模拟操作系统/应用层并发。

例如单台服务器4个数据库，则`fio bs=4k iodepth=32 numjobs=4`。

`iodepth`对应单个线程的队列深度，用于存储设备并发能力测试

`numjobs`对应多个线程并发，用于测试操作系统/应用层并发能力

### 综合基准测试

|测试项|测试工具|参考业务场景|
|---|---|---|
|综合性能指数|UnixBench|横向比较整机性能|

## 测试过程

### AMD 9F14平台测试

#### 安装CentOS 7.9.2009

替换源为清华大学CentOS-Vault源

```shell
sed -e "s|^mirrorlist=|#mirrorlist=|g" \
    -e "s|^#baseurl=http://mirror.centos.org/centos/\$releasever|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos-vault/7.9.2009|g" \
    -e "s|^#baseurl=http://mirror.centos.org/\$contentdir/\$releasever|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos-vault/7.9.2009|g" \
    -i.bak \
    /etc/yum.repos.d/CentOS-*.repo
```

该命令执行后会将原本的所有源配置文件备份为带`.bak`后缀名的备份

```shell
# 启用bash扩展通配符
shopt -s extglob

# 使用通配符快速删除不带.bak的文件
rm !(*.bak) -f

# 使用for循环快速去掉.bak后缀
for f in *.bak;do mv -- "$f" "${f%.bak}";done
```

`yum makecache`更新源

`yum install vim`安装vim编辑器

```shell
# 更新源
yum makecache
# 安装vim
yum install vim
# 编辑ssh配置文件
vim /etc/ssh/sshd_config
# 设置心跳
# 取消注释，设置为每60秒发送一次心跳重复9999999次
ClientAliveInterval 60
ClientAliveCountMax 99999
# 设置允许root用户登录
# 取消注释并配置为yes
PermitRootLogin yes
# 重启ssh服务
systemctl restart sshd
```

#### 准备CPU的Linpack测试

```shell
# 基础环境
yum install gcc gcc-c++ gcc-gfortran cmake python3 zlib* -y
# 安装OpenBLAS
yum install -y epel-release
yum install -y openblas openblas-devel
# 安装OpenMPI
yum install openmpi openmpi-devel
# 找到MPI的位置
find /usr -name "mpicc" 2>/dev/null
# 我的输出如下
/usr/lib64/openmpi/bin/mpicc
# 添加MPI到环境变量
echo 'export PATH=/usr/lib64/openmpi/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/lib64/openmpi/lib:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
# 临时生效
export PATH=/usr/lib64/openmpi/bin:$PATH
export LD_LIBRARY_PATH=/usr/lib64/openmpi/lib:$LD_LIBRARY_PATH

# 下载High Performance Linpack
# 去官网检查最新版https://www.netlib.org/benchmark/hpl/
wget https://www.netlib.org/benchmark/hpl/hpl-2.3.tar.gz
tar xvf hpl-2.3.tar.gz
mv hpl-2.3 hpl
mv hpl ~/
cd ~/hpl

# 从模板创建副本并改动编译器参数
# INTEL使用Make.Linux_Intel64
# AMD使用Make.Linux_ATHLON_FBLAS
cp setup/Make.Linux_ATHLON_FBLAS ./Make.AMD_OpenBLAS
vim Make.AMD_OpenBLAS

# 64行的ARCH自定义名称，需要和文件名后缀一致，如Make.AMD_OpenBLAS
# 后续make编译时会用到，如make arch=AMD_OpenBLAS
ARCH = AMD_OpenBLAS

# 配置openblas通用开源方案，保持测试结果的中立
# 避免MKL和AOCL BLIS/LibFLAME对于INTEL AMD的专项优化
# 修改配置使HPL走CBLAS接口，而不是老的Fortran BLAS
# 在配置文件中找到
HPL_DEFS     = $(F2CDEFS) $(HPL_OPTS) $(HPL_INCLUDES)
# 在这一行的上方加入以下内容
BLASLIB = -lopenblas
# 在末尾加上 -DHPL_CALL_CBLAS
HPL_DEFS     = $(F2CDEFS) $(HPL_OPTS) $(HPL_INCLUDES) -DHPL_CALL_CBLAS
# 找到CCFLAGS，添加-march=native
CCFLAGS      = $(HPL_DEFS) -fomit-frame-pointer -O3 -funroll-loops -W -Wall -march=native

# 默认的配置如下
LAdir        = $(HOME)/netlib/ARCHIVES/Linux_ATHLON
LAinc        =
LAlib        = $(LAdir)/libf77blas.a $(LAdir)/libatlas.a
# 修改为
LAdir   = /usr/lib64/openblas  # 或者你的 OpenBLAS 安装路径
LAinc   =
LAlib   = -lopenblas

# # 指定OpenMPI
# MPdir   = /usr
# MPinc   = -I/usr/include/openmpi-x86_64
# MPlib   = -L/usr/lib64 -lmpi

# 改为直接使用mpicc编译
# 修改CC
CC      = mpicc
# 在HPL_LIBS = $(HPLlib) $(LAlib) $(MPlib)的上方加入
MPlib = -lmpi
MPIinc = -I/usr/lib64/openmpi/include
MPilib = -L/usr/lib64/openmpi/lib -lmpi

# 复查一下系统中有没有openblas
ldconfig -p | grep openblas
# 输出通常如下所示
libopenblas64_.so.0 (libc6,x86-64) => /lib64/libopenblas64_.so.0
libopenblas64.so.0 (libc6,x86-64) => /lib64/libopenblas64.so.0
libopenblasp64_.so.0 (libc6,x86-64) => /lib64/libopenblasp64_.so.0
libopenblasp64.so.0 (libc6,x86-64) => /lib64/libopenblasp64.so.0
libopenblasp.so.0 (libc6,x86-64) => /lib64/libopenblasp.so.0
libopenblaso64_.so.0 (libc6,x86-64) => /lib64/libopenblaso64_.so.0
libopenblaso64.so.0 (libc6,x86-64) => /lib64/libopenblaso64.so.0
libopenblaso.so.0 (libc6,x86-64) => /lib64/libopenblaso.so.0
libopenblas.so.0 (libc6,x86-64) => /lib64/libopenblas.so.0

# 将g77指向gfortran
ln -s /usr/bin/gfortran /usr/bin/g77
# 编译HPL
make -f Make.top build_src arch=AMD_OpenBLAS
make -f Make.top build_tst arch=AMD_OpenBLAS


# 编辑HPL.dat
cd bin/AMD_OpenBLAS
mv HPL.dat HPL.dat.bak
vim HPL.dat

# HPL.dat范例，参数及其解析详见下方表格
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out
6
3            # of problems sizes (N)
160000 180000 200000  Ns
2            # of NBs
192 256      NBs
0            PMAP process mapping (0=Row-,1=Column-major)
4            # of process grids (P x Q)
8 12 16 24   Ps
12 8 6 4     Qs
16.0         threshold
3            # of panel fact
0 1 2        PFACTs (0=left, 1=Crout, 2=Right)
2            # of recursive stopping criterium
2 4          NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
3            # of recursive panel fact.
0 1 2        RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
1            DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64           swapping threshold
0            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)

# 禁用防火墙
systemctl stop firewalld
setenforce 0
# 开始运行
mpirun --allow-run-as-root -np 96 --map-by core --bind-to core ./xhpl

# 使用htop查看硬件负载
yum install -y htop
htop

# 测试结果范例
--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=   4.05060742e-04 ...... PASSED
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR11R2L4      160000   256     8    12            1624.73             1.6807e+03
HPL_pdgesv() start time Sat Sep 13 08:19:27 2025

HPL_pdgesv() end time   Sat Sep 13 08:46:32 2025

--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=   4.22512254e-04 ...... PASSED
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR11R2C2      160000   256     8    12            1624.25             1.6812e+03
HPL_pdgesv() start time Sat Sep 13 08:46:47 2025

HPL_pdgesv() end time   Sat Sep 13 09:13:51 2025

--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=   4.05060742e-04 ...... PASSED
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR11R2C4      160000   256     8    12            1628.17             1.6772e+03
HPL_pdgesv() start time Sat Sep 13 09:14:06 2025

HPL_pdgesv() end time   Sat Sep 13 09:41:14 2025

--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=   4.22512254e-04 ...... PASSED
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR11R2R2      160000   256     8    12            1629.43             1.6759e+03
HPL_pdgesv() start time Sat Sep 13 09:41:29 2025

HPL_pdgesv() end time   Sat Sep 13 10:08:38 2025

--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=   4.05060742e-04 ...... PASSED
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR11R2R4      160000   256     8    12            1626.10             1.6793e+03
HPL_pdgesv() start time Sat Sep 13 10:08:53 2025

HPL_pdgesv() end time   Sat Sep 13 10:35:59 2025

--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=   3.84591462e-04 ...... PASSED
--------------------------------------------------------------------------
mpirun noticed that process rank 3 with PID 43080 on node localhost exited on signal 9 (Killed).
--------------------------------------------------------------------------
```

##### HPL.dat的参数及其说明

在线生成HPL.dat文件的网站[HPL.dat](https://www.advancedclustering.com/act_kb/tune-hpl-dat-file/)

|参数|说明|
|---|---|
|Nodes|对应CPU数量|
|Cores per Node|每个CPU多少核|
|Memory per Node(MB)|每个CPU有多少MB内存|
|Block Size(NB)|HPL运算的块大小|

NB 块大小计算方式：

**设置适当的块大小，使数据块能够很好的放入CPU的高速缓存（L2/L3 Cache），如果数据块不能放入高速缓存，则不得不从慢得多的主内存RAM中进行读取，从而导致性能瓶颈。**

NB最好是PQ的整数倍，以我的AMD 9A14为例，L3为384MB，96核心

HPL将矩阵N分块成NB*NB的小块，然后分布在一个二维进程网格P行Q列上

所以如果任何一方过长，就会造成通信路径变长，从而导致性能开销大

为了使性能达到最优，需要使这个二维网格接近正方形，也就是PQ值相近，且同时P*Q需要等于核心数，以确保每个核心都有数据块在计算

寻找正方形则直接开方，96接近100，则100开方10，96/10=9.6，96/9=10.66，96/8=12，取8*12做网格

PQ数值为8*12，接下来计算NB，NB最好是PQ的整数倍，且需要能放入L3 Cache

Double精度每个元素8字节，则L3 384MB按照PQ计算为384/96=4MB，每个进程4MB

如果NB太小，会导致每次发送过于碎片化，增大通信开销，太大则可能导致Cache容量不足，通常取一半值

4*1024*1024=4194304Byte/8=524288Double开方约为724，则NB为724*724，取一半则为362*362，优化对齐（64字节CPU，矢量寄存器SIMD指令一次性并行处理一批数据，例如AVX-512一次处理8个double）后取近似值384

最终计算出PQ为8*12，NB为384

在线生成后的HPL.dat如下

```shell
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any) 
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
165120         Ns
1            # of NBs
384           NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
8            Ps
12            Qs
16.0         threshold
1            # of panel fact
2            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
1            DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64           swapping threshold
0            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
##### This line (no. 32) is ignored (it serves as a separator). ######
0                               Number of additional problem sizes for PTRANS
1200 10000 30000                values of N
0                               number of additional blocking sizes for PTRANS
40 9 8 13 13 20 16 32 64        values of NB
```

|行号|参数内容 |说明|
|---|---|---|
|1|
